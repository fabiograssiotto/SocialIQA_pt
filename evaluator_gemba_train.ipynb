{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file implements translation evaluations using a modified GEMBA prompt system for the train dataset. Due to OpenAI rate limits, the evaluations are run with chunks of the training set producing split results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (0.2.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-openai in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-openai) (0.2.5)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-openai) (1.34.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.77)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in d:\\development\\conda-envs\\ml_proj\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.26.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install langchain\n",
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Langchain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL_NAME=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function to set up the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openai_key():\n",
    "    try:\n",
    "        # Open and read the entire content of the file\n",
    "        with open(\"openai-key.txt\", 'r') as file:\n",
    "            contents = file.read()\n",
    "        \n",
    "        return contents\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file does not exist.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Handle other potential exceptions (e.g., permission errors)\n",
    "        print(f\"An error occurred while reading the file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "openai_key = load_openai_key()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\\\n",
    "You are a helpful evaluator of the quality of translations.\n",
    "Score the following translations from English to Portuguese on a continuous scale from 0 to 100, \n",
    "where a score of zero means \"no meaning preserved\" and score of one hundred means\n",
    "\"perfect meaning and grammar\".\n",
    "\"\"\"\n",
    "\n",
    "human = \"\"\"\\\n",
    "En: {source_seg}\n",
    "Pt 1: \"{target_seg1}\" \n",
    "Pt 2: \"{target_seg2}\"\n",
    "Pt 3: \"{target_seg3}\"\n",
    "Reply with only the number scores of your evaluation, in a python list:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat\n",
    "response = chain.invoke(input={\"source_seg\": \"There are more things between heaven and earth\",\n",
    "                    \"target_seg1\": \"Existem mais coisas entre o céu e a terra\",\n",
    "                    \"target_seg2\": \"Existem coisas entre o céu e a terra\",\n",
    "                    \"target_seg3\": \"Existem coisas entre o paraíso e a terra\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 80, 60]\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all source and target language datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data/train_sets'\n",
    "num_chunks = len(os.listdir(folder_path))\n",
    "\n",
    "df_train_sets = []\n",
    "for i in range(num_chunks):\n",
    "    file_path = folder_path + '/train_' + str(i+1) + '.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    df_train_sets.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answerA</th>\n",
       "      <th>answerB</th>\n",
       "      <th>answerC</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Even though she had homework to do that night,...</td>\n",
       "      <td>What will Jesse want to do next?</td>\n",
       "      <td>read homework to Skylar</td>\n",
       "      <td>help Skylar finish</td>\n",
       "      <td>skip her studying</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After school, Casey met the friend at a bar so...</td>\n",
       "      <td>Why did Casey do this?</td>\n",
       "      <td>have a good idea of the material</td>\n",
       "      <td>goof around with a friend</td>\n",
       "      <td>have a few drinks and leave</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesse went quickly to their mother and their m...</td>\n",
       "      <td>How would Jesse feel afterwards?</td>\n",
       "      <td>wasting their time</td>\n",
       "      <td>that they are a good child</td>\n",
       "      <td>that their mother always calls them</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robin knew that Kai really wanted her to the l...</td>\n",
       "      <td>Why did Robin do this?</td>\n",
       "      <td>paid her to say that she liked it</td>\n",
       "      <td>she never really liked Kai or her fashion</td>\n",
       "      <td>she knew Kai wanted Robin to like the outfit</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addison slept well last night after playing ba...</td>\n",
       "      <td>Why did Addison do this?</td>\n",
       "      <td>regain her energy</td>\n",
       "      <td>hit a home run</td>\n",
       "      <td>run the bases</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Bailey scarred the hell out of Alex because Al...</td>\n",
       "      <td>What will happen to Alex?</td>\n",
       "      <td>try to beat Alex up</td>\n",
       "      <td>have no friend</td>\n",
       "      <td>get a restraining order against Alex</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Quinn drank a lot of alcohol while they were o...</td>\n",
       "      <td>How would Quinn feel afterwards?</td>\n",
       "      <td>a hardcore party person</td>\n",
       "      <td>sober</td>\n",
       "      <td>hungover</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Carson sent Bailey's lunch to school after he ...</td>\n",
       "      <td>What will Carson want to do next?</td>\n",
       "      <td>remember bailey's lunch</td>\n",
       "      <td>make sure the lunch gets there</td>\n",
       "      <td>say sorry multiple times</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Jan decided to watch the news today because a ...</td>\n",
       "      <td>Why did Jan watch the news?</td>\n",
       "      <td>watched because the news was being attacked</td>\n",
       "      <td>watched because a war began last night</td>\n",
       "      <td>watched because her town was broke</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Cameron locked the car behind Taylor so he cou...</td>\n",
       "      <td>How would Taylor feel as a result?</td>\n",
       "      <td>angry at his mom</td>\n",
       "      <td>ready to go home</td>\n",
       "      <td>like he was safe</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Even though she had homework to do that night,...   \n",
       "1     After school, Casey met the friend at a bar so...   \n",
       "2     Jesse went quickly to their mother and their m...   \n",
       "3     Robin knew that Kai really wanted her to the l...   \n",
       "4     Addison slept well last night after playing ba...   \n",
       "...                                                 ...   \n",
       "4995  Bailey scarred the hell out of Alex because Al...   \n",
       "4996  Quinn drank a lot of alcohol while they were o...   \n",
       "4997  Carson sent Bailey's lunch to school after he ...   \n",
       "4998  Jan decided to watch the news today because a ...   \n",
       "4999  Cameron locked the car behind Taylor so he cou...   \n",
       "\n",
       "                                question  \\\n",
       "0       What will Jesse want to do next?   \n",
       "1                 Why did Casey do this?   \n",
       "2       How would Jesse feel afterwards?   \n",
       "3                 Why did Robin do this?   \n",
       "4               Why did Addison do this?   \n",
       "...                                  ...   \n",
       "4995           What will happen to Alex?   \n",
       "4996    How would Quinn feel afterwards?   \n",
       "4997   What will Carson want to do next?   \n",
       "4998         Why did Jan watch the news?   \n",
       "4999  How would Taylor feel as a result?   \n",
       "\n",
       "                                          answerA  \\\n",
       "0                         read homework to Skylar   \n",
       "1                have a good idea of the material   \n",
       "2                              wasting their time   \n",
       "3               paid her to say that she liked it   \n",
       "4                               regain her energy   \n",
       "...                                           ...   \n",
       "4995                          try to beat Alex up   \n",
       "4996                      a hardcore party person   \n",
       "4997                      remember bailey's lunch   \n",
       "4998  watched because the news was being attacked   \n",
       "4999                             angry at his mom   \n",
       "\n",
       "                                        answerB  \\\n",
       "0                            help Skylar finish   \n",
       "1                     goof around with a friend   \n",
       "2                    that they are a good child   \n",
       "3     she never really liked Kai or her fashion   \n",
       "4                                hit a home run   \n",
       "...                                         ...   \n",
       "4995                             have no friend   \n",
       "4996                                      sober   \n",
       "4997             make sure the lunch gets there   \n",
       "4998     watched because a war began last night   \n",
       "4999                           ready to go home   \n",
       "\n",
       "                                           answerC correct  \n",
       "0                                skip her studying       B  \n",
       "1                      have a few drinks and leave       A  \n",
       "2              that their mother always calls them       B  \n",
       "3     she knew Kai wanted Robin to like the outfit       C  \n",
       "4                                    run the bases       A  \n",
       "...                                            ...     ...  \n",
       "4995          get a restraining order against Alex       B  \n",
       "4996                                      hungover       C  \n",
       "4997                      say sorry multiple times       B  \n",
       "4998            watched because her town was broke       B  \n",
       "4999                              like he was safe       A  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'translated/train_sets'\n",
    "num_chunks = len(os.listdir(folder_path))\n",
    "\n",
    "df_train_pt_sets = []\n",
    "for i in range(num_chunks):\n",
    "    file_path = folder_path + '/train_pt_' + str(i+1) + '.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    df_train_pt_sets.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_3</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>question_3</th>\n",
       "      <th>answerA_1</th>\n",
       "      <th>answerA_2</th>\n",
       "      <th>answerA_3</th>\n",
       "      <th>answerB_1</th>\n",
       "      <th>answerB_2</th>\n",
       "      <th>answerB_3</th>\n",
       "      <th>answerC_1</th>\n",
       "      <th>answerC_2</th>\n",
       "      <th>answerC_3</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mesmo que ela tivesse trabalho de casa para fa...</td>\n",
       "      <td>Embora tivesse realizado trabalho doméstico pa...</td>\n",
       "      <td>Mesmo tendo de fazer o dever de casa naquela n...</td>\n",
       "      <td>O que Jesse vai querer fazer a seguir?</td>\n",
       "      <td>O que Jesse quer fazer em seguida?</td>\n",
       "      <td>O que é que o Jesse vai querer fazer a seguir?</td>\n",
       "      <td>Leia lição de casa para Skylar</td>\n",
       "      <td>Leia o serviço de casa para Skylar</td>\n",
       "      <td>Leia os trabalhos de casa à Skylar.</td>\n",
       "      <td>Ajuda Skylar finish</td>\n",
       "      <td>Ajuda de acabamento Skylar</td>\n",
       "      <td>Ajudem a Skylar a terminar .</td>\n",
       "      <td>ignorá-la estudando</td>\n",
       "      <td>skip seus estudos</td>\n",
       "      <td>Não a deixes estudar.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Depois da escola, Casey conheceu o amigo em um...</td>\n",
       "      <td>Após a escola, Casey conheceu o amigo em um ba...</td>\n",
       "      <td>Depois da escola, o Casey conheceu a amiga num...</td>\n",
       "      <td>Porque é que o Casey fez isto?</td>\n",
       "      <td>Por que o Casey?</td>\n",
       "      <td>Porque fez o Casey isto?</td>\n",
       "      <td>Tenha uma boa ideia do material</td>\n",
       "      <td>têm uma boa ideia do material</td>\n",
       "      <td>ter uma boa ideia do material</td>\n",
       "      <td>goof em torno de com um amigo</td>\n",
       "      <td>náuseas</td>\n",
       "      <td>brincar com um amigo</td>\n",
       "      <td>Beba alguns drinques e vá embora</td>\n",
       "      <td>tem algumas bebidas e folhas.</td>\n",
       "      <td>Bebam um copo e vão-se embora .</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesse foi rapidamente para sua mãe e sua mãe d...</td>\n",
       "      <td>Jesse chegou rapidamente à mãe e a mãe lhes di...</td>\n",
       "      <td>Jesse foi rapidamente para a mãe deles e a mãe...</td>\n",
       "      <td>Como Jesse se sentiria depois?</td>\n",
       "      <td>Como Jesse se sentiria depois?</td>\n",
       "      <td>Como se sentiria o Jesse depois?</td>\n",
       "      <td>Desperdiçando o seu tempo</td>\n",
       "      <td>desperdícios</td>\n",
       "      <td>a perder o seu tempo.</td>\n",
       "      <td>que eles são uma boa criança</td>\n",
       "      <td>que são uma criança boa</td>\n",
       "      <td>Que são uma boa criança.</td>\n",
       "      <td>que sua mãe sempre os chama</td>\n",
       "      <td>que a mãe sempre os chama</td>\n",
       "      <td>que a mãe sempre os chama</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robin sabia que Kai realmente queria que ela g...</td>\n",
       "      <td>Robin sabia que Kai realmente queria que ela f...</td>\n",
       "      <td>A Robin sabia que o Kai queria que ela gostass...</td>\n",
       "      <td>Porque é que a Robin fez isto?</td>\n",
       "      <td>Por que Robin fez isso?</td>\n",
       "      <td>Porque é que a Robin fez isto?</td>\n",
       "      <td>Pagou-lhe para dizer que ela gostou</td>\n",
       "      <td>pagou-lhe que ela gostava de</td>\n",
       "      <td>Pagou-lhe para dizer que gostava.</td>\n",
       "      <td>ela nunca gostou muito de Kai ou sua moda</td>\n",
       "      <td>nunca gostava mesmo de Kai ou de sua moda</td>\n",
       "      <td>Ela nunca gostou muito do Kai ou da moda dela .</td>\n",
       "      <td>Ela sabia que Kai queria que Robin gostasse da...</td>\n",
       "      <td>ela sabia que Kai queria Robin gostar do outfit</td>\n",
       "      <td>Ela sabia que o Kai queria que a Robin gostass...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Addison dormiu bem ontem à noite depois de j...</td>\n",
       "      <td>O adison dormiu bem na noite seguinte ao jogo ...</td>\n",
       "      <td>Addison dormiu bem ontem à noite depois de jog...</td>\n",
       "      <td>Porque é que a Addison fez isto?</td>\n",
       "      <td>Por que o Addison fez isso?</td>\n",
       "      <td>Porque é que a Addison fez isto?</td>\n",
       "      <td>Recupere sua energia</td>\n",
       "      <td>recuperar sua energia</td>\n",
       "      <td>Recupera a sua energia.</td>\n",
       "      <td>Atingir um home run</td>\n",
       "      <td>batimentos em casa</td>\n",
       "      <td>bateu um home run</td>\n",
       "      <td>Executar as bases</td>\n",
       "      <td>Executar as bases</td>\n",
       "      <td>- Não .</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Bailey tirou as cicatrizes de Alex porque Alex...</td>\n",
       "      <td>Bailey cicatriou o inferno de Alex porque Alex...</td>\n",
       "      <td>A Bailey deixou cicatrizes no Alex porque ele ...</td>\n",
       "      <td>O que vai acontecer com Alex?</td>\n",
       "      <td>O que acontecerá com Alex?</td>\n",
       "      <td>O que vai acontecer com o Alex?</td>\n",
       "      <td>tentar bater Alex para cima</td>\n",
       "      <td>tentar vencer Alex</td>\n",
       "      <td>Tentei bater no Alex .</td>\n",
       "      <td>não tem amigo</td>\n",
       "      <td>Não tem amigos</td>\n",
       "      <td>Não tenho amigo,</td>\n",
       "      <td>obter uma ordem de restrição contra Alex</td>\n",
       "      <td>obter uma ordem de retenção contra Alex</td>\n",
       "      <td>Obter uma ordem de restrição contra o Alex</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Quinn bebeu muito álcool enquanto eles estavam...</td>\n",
       "      <td>Quinn bebe muito álcool enquanto eles estavam ...</td>\n",
       "      <td>Quinn bebeu muito álcool enquanto estavam numa...</td>\n",
       "      <td>Como Quinn se sentiria depois?</td>\n",
       "      <td>Como se sentiria Quinn depois?</td>\n",
       "      <td>Como se sentiria o Quinn depois?</td>\n",
       "      <td>uma pessoa de festa hardcore</td>\n",
       "      <td>uma pessoa emblemática</td>\n",
       "      <td>Uma pessoa de festas hardcore</td>\n",
       "      <td>sóbria</td>\n",
       "      <td>nã</td>\n",
       "      <td>sóbrio</td>\n",
       "      <td>ressaca</td>\n",
       "      <td>náusea</td>\n",
       "      <td>ressaca</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Carson mandou o almoço de Bailey para a escola...</td>\n",
       "      <td>Carson enviou o almoço de Bailey para a escola...</td>\n",
       "      <td>O Carson mandou o almoço do Bailey para a esco...</td>\n",
       "      <td>O que Carson vai querer fazer a seguir?</td>\n",
       "      <td>O que queremos por Carson?</td>\n",
       "      <td>O que é que o Carson vai querer fazer a seguir?</td>\n",
       "      <td>Lembra-te do almoço do Bailey</td>\n",
       "      <td>lembrar o almoço do baile</td>\n",
       "      <td>Lembras-te do almoço da Bailey?</td>\n",
       "      <td>Certifique-se de que o almoço chegue lá</td>\n",
       "      <td>esqueça o almoço</td>\n",
       "      <td>Certifica-te que o almoço chega lá .</td>\n",
       "      <td>pedir desculpas várias vezes</td>\n",
       "      <td>digam que se arrependem múltiplos tempos</td>\n",
       "      <td>Peço desculpa várias vezes.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Jan decidiu assistir a notícia hoje porque uma...</td>\n",
       "      <td>Jan decidiu assistir hoje a notícia porque uma...</td>\n",
       "      <td>Jan decidiu ver as notícias hoje porque a guer...</td>\n",
       "      <td>Porque é que o Jan viu a notícia?</td>\n",
       "      <td>Por que Jan assistiu a notícia?</td>\n",
       "      <td>Porque é que a Jan assistiu às notícias?</td>\n",
       "      <td>Assistiu porque a notícia estava sendo atacada</td>\n",
       "      <td>assistido, pois a notícia estava sendo atacada</td>\n",
       "      <td>Assisti porque as notícias estavam a ser ataca...</td>\n",
       "      <td>Assistiu porque uma guerra começou ontem à noite</td>\n",
       "      <td>visto porque uma guerra começou a</td>\n",
       "      <td>Viste porque a guerra começou ontem à noite</td>\n",
       "      <td>Observando porque sua cidade estava falida</td>\n",
       "      <td>assistido por sua cidade estar quebrada</td>\n",
       "      <td>Viste porque a cidade dela estava falida.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Cameron trancou o carro atrás de Taylor para q...</td>\n",
       "      <td>Cameron bloqueou o carro atrás de Taylor para ...</td>\n",
       "      <td>O Cameron trancou o carro atrás da Taylor para...</td>\n",
       "      <td>Como Taylor se sentiria como resultado?</td>\n",
       "      <td>Como seria que Taylor sentisse como resultado?</td>\n",
       "      <td>Como se sentiria Taylor?</td>\n",
       "      <td>Irritado com sua mãe</td>\n",
       "      <td>náusea na mãe</td>\n",
       "      <td>zangado com a mãe dele.</td>\n",
       "      <td>Pronto para ir para casa</td>\n",
       "      <td>Pronto para ir para casa</td>\n",
       "      <td>Pronto para ir para casa .</td>\n",
       "      <td>Como se estivesse seguro</td>\n",
       "      <td>como ele foi seguro</td>\n",
       "      <td>Como se estivesse a salvo.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context_1  \\\n",
       "0     Mesmo que ela tivesse trabalho de casa para fa...   \n",
       "1     Depois da escola, Casey conheceu o amigo em um...   \n",
       "2     Jesse foi rapidamente para sua mãe e sua mãe d...   \n",
       "3     Robin sabia que Kai realmente queria que ela g...   \n",
       "4     A Addison dormiu bem ontem à noite depois de j...   \n",
       "...                                                 ...   \n",
       "4995  Bailey tirou as cicatrizes de Alex porque Alex...   \n",
       "4996  Quinn bebeu muito álcool enquanto eles estavam...   \n",
       "4997  Carson mandou o almoço de Bailey para a escola...   \n",
       "4998  Jan decidiu assistir a notícia hoje porque uma...   \n",
       "4999  Cameron trancou o carro atrás de Taylor para q...   \n",
       "\n",
       "                                              context_2  \\\n",
       "0     Embora tivesse realizado trabalho doméstico pa...   \n",
       "1     Após a escola, Casey conheceu o amigo em um ba...   \n",
       "2     Jesse chegou rapidamente à mãe e a mãe lhes di...   \n",
       "3     Robin sabia que Kai realmente queria que ela f...   \n",
       "4     O adison dormiu bem na noite seguinte ao jogo ...   \n",
       "...                                                 ...   \n",
       "4995  Bailey cicatriou o inferno de Alex porque Alex...   \n",
       "4996  Quinn bebe muito álcool enquanto eles estavam ...   \n",
       "4997  Carson enviou o almoço de Bailey para a escola...   \n",
       "4998  Jan decidiu assistir hoje a notícia porque uma...   \n",
       "4999  Cameron bloqueou o carro atrás de Taylor para ...   \n",
       "\n",
       "                                              context_3  \\\n",
       "0     Mesmo tendo de fazer o dever de casa naquela n...   \n",
       "1     Depois da escola, o Casey conheceu a amiga num...   \n",
       "2     Jesse foi rapidamente para a mãe deles e a mãe...   \n",
       "3     A Robin sabia que o Kai queria que ela gostass...   \n",
       "4     Addison dormiu bem ontem à noite depois de jog...   \n",
       "...                                                 ...   \n",
       "4995  A Bailey deixou cicatrizes no Alex porque ele ...   \n",
       "4996  Quinn bebeu muito álcool enquanto estavam numa...   \n",
       "4997  O Carson mandou o almoço do Bailey para a esco...   \n",
       "4998  Jan decidiu ver as notícias hoje porque a guer...   \n",
       "4999  O Cameron trancou o carro atrás da Taylor para...   \n",
       "\n",
       "                                   question_1  \\\n",
       "0      O que Jesse vai querer fazer a seguir?   \n",
       "1              Porque é que o Casey fez isto?   \n",
       "2              Como Jesse se sentiria depois?   \n",
       "3              Porque é que a Robin fez isto?   \n",
       "4            Porque é que a Addison fez isto?   \n",
       "...                                       ...   \n",
       "4995            O que vai acontecer com Alex?   \n",
       "4996           Como Quinn se sentiria depois?   \n",
       "4997  O que Carson vai querer fazer a seguir?   \n",
       "4998        Porque é que o Jan viu a notícia?   \n",
       "4999  Como Taylor se sentiria como resultado?   \n",
       "\n",
       "                                          question_2  \\\n",
       "0                 O que Jesse quer fazer em seguida?   \n",
       "1                                   Por que o Casey?   \n",
       "2                     Como Jesse se sentiria depois?   \n",
       "3                            Por que Robin fez isso?   \n",
       "4                        Por que o Addison fez isso?   \n",
       "...                                              ...   \n",
       "4995                      O que acontecerá com Alex?   \n",
       "4996                  Como se sentiria Quinn depois?   \n",
       "4997                      O que queremos por Carson?   \n",
       "4998                 Por que Jan assistiu a notícia?   \n",
       "4999  Como seria que Taylor sentisse como resultado?   \n",
       "\n",
       "                                           question_3  \\\n",
       "0      O que é que o Jesse vai querer fazer a seguir?   \n",
       "1                            Porque fez o Casey isto?   \n",
       "2                    Como se sentiria o Jesse depois?   \n",
       "3                      Porque é que a Robin fez isto?   \n",
       "4                    Porque é que a Addison fez isto?   \n",
       "...                                               ...   \n",
       "4995                  O que vai acontecer com o Alex?   \n",
       "4996                 Como se sentiria o Quinn depois?   \n",
       "4997  O que é que o Carson vai querer fazer a seguir?   \n",
       "4998         Porque é que a Jan assistiu às notícias?   \n",
       "4999                         Como se sentiria Taylor?   \n",
       "\n",
       "                                           answerA_1  \\\n",
       "0                     Leia lição de casa para Skylar   \n",
       "1                    Tenha uma boa ideia do material   \n",
       "2                          Desperdiçando o seu tempo   \n",
       "3                Pagou-lhe para dizer que ela gostou   \n",
       "4                               Recupere sua energia   \n",
       "...                                              ...   \n",
       "4995                     tentar bater Alex para cima   \n",
       "4996                    uma pessoa de festa hardcore   \n",
       "4997                   Lembra-te do almoço do Bailey   \n",
       "4998  Assistiu porque a notícia estava sendo atacada   \n",
       "4999                            Irritado com sua mãe   \n",
       "\n",
       "                                           answerA_2  \\\n",
       "0                 Leia o serviço de casa para Skylar   \n",
       "1                      têm uma boa ideia do material   \n",
       "2                                       desperdícios   \n",
       "3                       pagou-lhe que ela gostava de   \n",
       "4                              recuperar sua energia   \n",
       "...                                              ...   \n",
       "4995                              tentar vencer Alex   \n",
       "4996                          uma pessoa emblemática   \n",
       "4997                       lembrar o almoço do baile   \n",
       "4998  assistido, pois a notícia estava sendo atacada   \n",
       "4999                                   náusea na mãe   \n",
       "\n",
       "                                              answerA_3  \\\n",
       "0                   Leia os trabalhos de casa à Skylar.   \n",
       "1                         ter uma boa ideia do material   \n",
       "2                                 a perder o seu tempo.   \n",
       "3                     Pagou-lhe para dizer que gostava.   \n",
       "4                               Recupera a sua energia.   \n",
       "...                                                 ...   \n",
       "4995                             Tentei bater no Alex .   \n",
       "4996                      Uma pessoa de festas hardcore   \n",
       "4997                    Lembras-te do almoço da Bailey?   \n",
       "4998  Assisti porque as notícias estavam a ser ataca...   \n",
       "4999                            zangado com a mãe dele.   \n",
       "\n",
       "                                             answerB_1  \\\n",
       "0                                  Ajuda Skylar finish   \n",
       "1                        goof em torno de com um amigo   \n",
       "2                         que eles são uma boa criança   \n",
       "3            ela nunca gostou muito de Kai ou sua moda   \n",
       "4                                  Atingir um home run   \n",
       "...                                                ...   \n",
       "4995                                     não tem amigo   \n",
       "4996                                            sóbria   \n",
       "4997           Certifique-se de que o almoço chegue lá   \n",
       "4998  Assistiu porque uma guerra começou ontem à noite   \n",
       "4999                          Pronto para ir para casa   \n",
       "\n",
       "                                      answerB_2  \\\n",
       "0                    Ajuda de acabamento Skylar   \n",
       "1                                       náuseas   \n",
       "2                       que são uma criança boa   \n",
       "3     nunca gostava mesmo de Kai ou de sua moda   \n",
       "4                            batimentos em casa   \n",
       "...                                         ...   \n",
       "4995                             Não tem amigos   \n",
       "4996                                         nã   \n",
       "4997                           esqueça o almoço   \n",
       "4998          visto porque uma guerra começou a   \n",
       "4999                   Pronto para ir para casa   \n",
       "\n",
       "                                            answerB_3  \\\n",
       "0                        Ajudem a Skylar a terminar .   \n",
       "1                                brincar com um amigo   \n",
       "2                            Que são uma boa criança.   \n",
       "3     Ela nunca gostou muito do Kai ou da moda dela .   \n",
       "4                                   bateu um home run   \n",
       "...                                               ...   \n",
       "4995                                 Não tenho amigo,   \n",
       "4996                                           sóbrio   \n",
       "4997             Certifica-te que o almoço chega lá .   \n",
       "4998      Viste porque a guerra começou ontem à noite   \n",
       "4999                       Pronto para ir para casa .   \n",
       "\n",
       "                                              answerC_1  \\\n",
       "0                                   ignorá-la estudando   \n",
       "1                      Beba alguns drinques e vá embora   \n",
       "2                           que sua mãe sempre os chama   \n",
       "3     Ela sabia que Kai queria que Robin gostasse da...   \n",
       "4                                     Executar as bases   \n",
       "...                                                 ...   \n",
       "4995           obter uma ordem de restrição contra Alex   \n",
       "4996                                            ressaca   \n",
       "4997                       pedir desculpas várias vezes   \n",
       "4998         Observando porque sua cidade estava falida   \n",
       "4999                           Como se estivesse seguro   \n",
       "\n",
       "                                            answerC_2  \\\n",
       "0                                   skip seus estudos   \n",
       "1                       tem algumas bebidas e folhas.   \n",
       "2                           que a mãe sempre os chama   \n",
       "3     ela sabia que Kai queria Robin gostar do outfit   \n",
       "4                                   Executar as bases   \n",
       "...                                               ...   \n",
       "4995          obter uma ordem de retenção contra Alex   \n",
       "4996                                           náusea   \n",
       "4997         digam que se arrependem múltiplos tempos   \n",
       "4998          assistido por sua cidade estar quebrada   \n",
       "4999                              como ele foi seguro   \n",
       "\n",
       "                                              answerC_3 correct  \n",
       "0                                 Não a deixes estudar.       B  \n",
       "1                       Bebam um copo e vão-se embora .       A  \n",
       "2                             que a mãe sempre os chama       B  \n",
       "3     Ela sabia que o Kai queria que a Robin gostass...       C  \n",
       "4                                               - Não .       A  \n",
       "...                                                 ...     ...  \n",
       "4995         Obter uma ordem de restrição contra o Alex       B  \n",
       "4996                                            ressaca       C  \n",
       "4997                        Peço desculpa várias vezes.       B  \n",
       "4998          Viste porque a cidade dela estava falida.       B  \n",
       "4999                         Como se estivesse a salvo.       A  \n",
       "\n",
       "[5000 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pt_sets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(i, df_src_lang, df_tgt_lang):\n",
    "\n",
    "        sentence_list = ['context', 'question', 'answerA', 'answerB', 'answerC']\n",
    "        english_str=\"\"\n",
    "        for sentence in sentence_list:\n",
    "                english_str += str(df_src_lang.loc[i, sentence])\n",
    "                english_str += \"\\n\"\n",
    "\n",
    "        portuguese_1=\"\"\n",
    "        sentence_list = ['context_1', 'question_1', 'answerA_1', 'answerB_1', 'answerC_1']\n",
    "        for sentence in sentence_list:\n",
    "                portuguese_1 += str(df_tgt_lang.loc[i, sentence])\n",
    "                portuguese_1 += \"\\n\"\n",
    "\n",
    "        portuguese_2=\"\"\n",
    "        sentence_list = ['context_2', 'question_2', 'answerA_2', 'answerB_2', 'answerC_2']\n",
    "        for sentence in sentence_list:\n",
    "                portuguese_2 += str(df_tgt_lang.loc[i, sentence])\n",
    "                portuguese_2 += \"\\n\"\n",
    "\n",
    "        portuguese_3=\"\"\n",
    "        sentence_list = ['context_3', 'question_3', 'answerA_3', 'answerB_3', 'answerC_3']\n",
    "        for sentence in sentence_list:\n",
    "                portuguese_3 += str(df_tgt_lang.loc[i, sentence])\n",
    "                portuguese_3 += \"\\n\"\n",
    "\n",
    "        return english_str, portuguese_1, portuguese_2, portuguese_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_translations(df_src_lang, df_tgt_lang):\n",
    "\n",
    "    total_tokens = 0\n",
    "\n",
    "    df_output = df_src_lang.copy()\n",
    "    df_output.loc[:, ['context', 'question', 'answerA', 'answerB', 'answerC']] = None\n",
    "    df_rankings = pd.DataFrame(columns=['MarianMT', 'Unicamp_T5', 'NLLB_1.3b'])\n",
    "\n",
    "    for i in tqdm(range(len(df_src_lang))):\n",
    "\n",
    "        # OpenAI call\n",
    "        chain = prompt | chat\n",
    "        english, translation_pt1, translation_pt2, translation_pt3 = create_sequences(i,\n",
    "                                                                                      df_src_lang,\n",
    "                                                                                      df_tgt_lang)\n",
    "        response = chain.invoke(input={\"source_seg\": english,\n",
    "                        \"target_seg1\": translation_pt1,\n",
    "                        \"target_seg2\": translation_pt2,\n",
    "                        \"target_seg3\": translation_pt3})\n",
    "        \n",
    "        total_tokens += response.response_metadata.get('token_usage').get('total_tokens')\n",
    "\n",
    "        results = ast.literal_eval(response.content)            \n",
    "        best = results.index(max(results))\n",
    "        \n",
    "        # Add to rankings dataset\n",
    "        df_rankings.loc[len(df_rankings)] = results\n",
    "        \n",
    "        # Copy to final dataset\n",
    "        col_list = ['context', 'question', 'answerA', 'answerB', 'answerC']\n",
    "        for col in col_list:\n",
    "            col_best = col + '_' + str(best+1)\n",
    "            best_result = df_tgt_lang.loc[i, col_best]\n",
    "            sentence_idx = col_list.index(col)\n",
    "            df_output.iat[i, sentence_idx] = best_result\n",
    "\n",
    "    print(f\"Total tokens used: {total_tokens}\")\n",
    "    \n",
    "    return df_output, df_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [52:25<00:00,  1.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used: 1539727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_1_final, df_train_1_rankings = get_best_translations(df_train_sets[0], df_train_pt_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_final.to_csv('translated/final/train_sets/train_1.csv')\n",
    "df_train_1_rankings.to_csv('rankings/train_sets/train_1_rankings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1055/5000 [33:22<2:04:48,  1.90s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\_base_client.py:999\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\httpx\\_models.py:761\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[1;32m--> 761\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train_2_final, df_train_2_rankings \u001b[38;5;241m=\u001b[39m get_best_translations(df_train_sets[\u001b[38;5;241m1\u001b[39m], df_train_pt_sets[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m, in \u001b[0;36mget_best_translations\u001b[1;34m(df_src_lang, df_tgt_lang)\u001b[0m\n\u001b[0;32m     12\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m chat\n\u001b[0;32m     13\u001b[0m english, translation_pt1, translation_pt2, translation_pt3 \u001b[38;5;241m=\u001b[39m create_sequences(i,\n\u001b[0;32m     14\u001b[0m                                                                               df_src_lang,\n\u001b[0;32m     15\u001b[0m                                                                               df_tgt_lang)\n\u001b[1;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_seg\u001b[39m\u001b[38;5;124m\"\u001b[39m: english,\n\u001b[0;32m     17\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_seg1\u001b[39m\u001b[38;5;124m\"\u001b[39m: translation_pt1,\n\u001b[0;32m     18\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_seg2\u001b[39m\u001b[38;5;124m\"\u001b[39m: translation_pt2,\n\u001b[0;32m     19\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_seg3\u001b[39m\u001b[38;5;124m\"\u001b[39m: translation_pt3})\n\u001b[0;32m     21\u001b[0m total_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mresponse_metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_usage\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m results \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(response\u001b[38;5;241m.\u001b[39mcontent)            \n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2495\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2494\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2495\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   2496\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    169\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    171\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    172\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    173\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    174\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    175\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    176\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    177\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    179\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    598\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    460\u001b[0m ]\n\u001b[0;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 446\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    447\u001b[0m                 m,\n\u001b[0;32m    448\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    449\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    451\u001b[0m             )\n\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    672\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    673\u001b[0m         )\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:537\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    536\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 537\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:606\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    608\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    609\u001b[0m             {\n\u001b[0;32m    610\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    611\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    612\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    613\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    614\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    615\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    616\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    617\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    618\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    620\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    621\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    622\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    623\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    624\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    625\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    626\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    627\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    628\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    629\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    630\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    631\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    632\u001b[0m             },\n\u001b[0;32m    633\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    634\u001b[0m         ),\n\u001b[0;32m    635\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    636\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    637\u001b[0m         ),\n\u001b[0;32m    638\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    639\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    640\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    922\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    923\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    924\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    925\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    926\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    927\u001b[0m     )\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1006\u001b[0m         options,\n\u001b[0;32m   1007\u001b[0m         cast_to,\n\u001b[0;32m   1008\u001b[0m         retries,\n\u001b[0;32m   1009\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1010\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1011\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32md:\\Development\\conda-envs\\ml_proj\\Lib\\site-packages\\openai\\_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1047\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1054\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1055\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1059\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_train_2_final, df_train_2_rankings = get_best_translations(df_train_sets[1], df_train_pt_sets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2_final.to_csv('translated/final/train_sets/train_2.csv')\n",
    "df_train_2_rankings.to_csv('rankings/train_sets/train_2_rankings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3_final, df_train_3_rankings = get_best_translations(df_train_sets[2], df_train_pt_sets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3_final.to_csv('translated/final/train_sets/train_3.csv')\n",
    "df_train_3_rankings.to_csv('rankings/train_sets/train_3_rankings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
